"use strict";(self.webpackChunkhashicorp_aws=self.webpackChunkhashicorp_aws||[]).push([[9231],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>m});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),u=p(a),m=i,d=u["".concat(l,".").concat(m)]||u[m]||h[m]||r;return a?n.createElement(d,s(s({ref:t},c),{},{components:a})):n.createElement(d,s({ref:t},c))}));function m(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,s=new Array(r);s[0]=u;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:i,s[1]=o;for(var p=2;p<r;p++)s[p]=a[p];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},3355:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>p});var n=a(7462),i=(a(7294),a(3905));const r={sidebar_position:3,title:"Elastic Stack (ELK)"},s=void 0,o={unversionedId:"elk",id:"elk",title:"Elastic Stack (ELK)",description:"Operations and SRE teams can use [hashicorp-aws] to safely manage ELK deployment using infrastructure as code",source:"@site/docs/elk.md",sourceDirName:".",slug:"/elk",permalink:"/hashicorp-aws/docs/elk",draft:!1,editUrl:"https://github.com/QubitPi/hashicorp-aws/tree/gh-pages/docs/elk.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,title:"Elastic Stack (ELK)"},sidebar:"tutorialSidebar",previous:{title:"How to Enable SSL Automatically Through HashiCorp AWS",permalink:"/hashicorp-aws/docs/ssl"},next:{title:"MLflow",permalink:"/hashicorp-aws/docs/mlflow"}},l={},p=[{value:"Getting ELK Deployer",id:"getting-elk-deployer",level:2},{value:"Configuring Deployment",id:"configuring-deployment",level:2},{value:"Authenticating to AWS",id:"authenticating-to-aws",level:3},{value:"Defining Config Directory",id:"defining-config-directory",level:3},{value:"Preparing for SSL",id:"preparing-for-ssl",level:4},{value:"Nginx",id:"nginx",level:5},{value:"Defining Packer Variables",id:"defining-packer-variables",level:4},{value:"Defining Terraform Variables",id:"defining-terraform-variables",level:4},{value:"Defining Config Directory Path",id:"defining-config-directory-path",level:4},{value:"Running Script",id:"running-script",level:2},{value:"Post Setup in EC2 Instance",id:"post-setup-in-ec2-instance",level:3},{value:"Logstash",id:"logstash",level:4}],c={toc:p};function h(e){let{components:t,...a}=e;return(0,i.kt)("wrapper",(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Operations and SRE teams can use ",(0,i.kt)("a",{parentName:"p",href:"https://qubitpi.github.io/hashicorp-aws/"},"hashicorp-aws")," to safely manage ELK deployment using infrastructure as code\nmethodology, which allows us to peer-reviewed infrastructure changes in an automated and controlled fashion."),(0,i.kt)("admonition",{title:"What is the ELK Stack?",type:"info"},(0,i.kt)("p",{parentName:"admonition"},"The ELK stack is an acronym used to describe a stack that comprises three popular projects: ",(0,i.kt)("a",{parentName:"p",href:"https://qubitpi.github.io/elasticsearch/"},"Elasticsearch"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://qubitpi.github.io/logstash/"},"Logstash"),", and ",(0,i.kt)("a",{parentName:"p",href:"https://qubitpi.github.io/kibana/"},"Kibana"),". Often referred to as Elasticsearch, the ELK stack gives us the ability to aggregate logs from\nall our systems and applications, analyze these logs, and create visualizations for application and infrastructure\nmonitoring, faster troubleshooting, security analytics, and more.")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Assuming ELK is a ",(0,i.kt)("em",{parentName:"strong"},"non-frequently deployed")," tech asset, ",(0,i.kt)("a",{parentName:"strong",href:"https://qubitpi.github.io/hashicorp-aws/"},"hashicorp-aws")," makes it a semi-automated deployment"),"."),(0,i.kt)("admonition",{type:"caution"},(0,i.kt)("p",{parentName:"admonition"},(0,i.kt)("a",{parentName:"p",href:"https://qubitpi.github.io/hashicorp-aws/"},"hashicorp-aws")," deploys ELK as a ",(0,i.kt)("a",{parentName:"p",href:"https://aws.amazon.com/ec2/instance-types/t2/"},"t2.large")," instance. This is because all\nElasticsearch, Kibana, and Logstash are contained in it, which can cause\n",(0,i.kt)("a",{parentName:"p",href:"https://stackoverflow.com/a/50022217"},"performance issue")," in small instance. ",(0,i.kt)("em",{parentName:"p"},"t2.large"),", by experiment, is the smallest\nsize that supports smooth runtime. For that, ",(0,i.kt)("strong",{parentName:"p"},"please be aware AWS credit charges shall incur afterward"))),(0,i.kt)("h2",{id:"getting-elk-deployer"},"Getting ELK Deployer"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/QubitPi/hashicorp-aws.git\ncd hashicorp/elk\n")),(0,i.kt)("h2",{id:"configuring-deployment"},"Configuring Deployment"),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"People may jump directly to the end of ",(0,i.kt)("a",{parentName:"p",href:"#configuring-deployment"},"this section")," to see what the final config looks like")),(0,i.kt)("h3",{id:"authenticating-to-aws"},"Authenticating to AWS"),(0,i.kt)("p",null,"Before we can build the AMI, we need to provide our AWS credentials to Packer and Terraform. These credentials have\npermissions to create, modify, and delete AMI images and EC2 instances."),(0,i.kt)("p",null,"To allow HashiCorp to access our IAM user credentials, set our AWS access key ID and secret key as environment\nvariables:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'AWS_ACCESS_KEY_ID="<YOUR_AWS_ACCESS_KEY_ID>"\nAWS_SECRET_ACCESS_KEY="<YOUR_AWS_SECRET_ACCESS_KEY>"\n')),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"The ",(0,i.kt)("em",{parentName:"p"},"IAM user")," associated with the credentials above must have the following ",(0,i.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_access-management.html"},"AWS permissions policies"),":"),(0,i.kt)("ul",{parentName:"admonition"},(0,i.kt)("li",{parentName:"ul"},"IAMFullAccess"),(0,i.kt)("li",{parentName:"ul"},"AmazonEC2FullAccess"),(0,i.kt)("li",{parentName:"ul"},"AmazonRoute53FullAccess"))),(0,i.kt)("h3",{id:"defining-config-directory"},"Defining Config Directory"),(0,i.kt)("h4",{id:"preparing-for-ssl"},"Preparing for SSL"),(0,i.kt)("p",null,"Please ",(0,i.kt)("a",{parentName:"p",href:"https://qubitpi.github.io/hashicorp-aws/blog/certbot"},"obtain SSL certificate and key")," and put them in 2 files. Let's call them ",(0,i.kt)("strong",{parentName:"p"},"server.crt"),"\n(certificate) and ",(0,i.kt)("strong",{parentName:"p"},"server.key")," (certificate key)"),(0,i.kt)("h5",{id:"nginx"},"Nginx"),(0,i.kt)("p",null,"We will have a Nginx reverse proxy to serve HTTPS and have a config file called ",(0,i.kt)("strong",{parentName:"p"},"nginx-ssl.conf"),":"),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"Replace ",(0,i.kt)("inlineCode",{parentName:"p"},"my-domain.com")," with the domain backed by the ",(0,i.kt)("a",{parentName:"p",href:"#preparing-for-ssl"},"SSL")," accordingly below")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-text"},"server {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n\n    root /var/www/html;\n\n    index index.html index.htm index.nginx-debian.html;\n\n    server_name _;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n\nserver {\n    root /var/www/html;\n\n    index index.html index.htm index.nginx-debian.html;\n    server_name my-domain.com;\n\n    location / {\n        proxy_pass http://localhost:5601;\n    }\n\n    listen [::]:443 ssl ipv6only=on;\n    listen 443 ssl;\n    ssl_certificate /etc/ssl/certs/server.crt;\n    ssl_certificate_key /etc/ssl/private/server.key;\n}\n\nserver {\n    if ($host = my-domain.com) {\n        return 301 https://$host$request_uri;\n    }\n\n    listen 80 ;\n    listen [::]:80 ;\n    server_name my-domain.com;\n    return 404;\n}\n")),(0,i.kt)("h4",{id:"defining-packer-variables"},"Defining Packer Variables"),(0,i.kt)("p",null,"Create a file named ",(0,i.kt)("strong",{parentName:"p"},"aws-elk.pkrvars.hcl")," with the following contents:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-hcl"},'aws_image_region           = "us-east-2"\nssl_cert_file_path         = "/absolute/path/to/server.crt"\nssl_cert_key_file_path     = "/absolute/path/to/server.key"\nssl_nginx_config_file_path = "/absolute/path/to/nginx-ssl.conf"\n')),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"aws_image_region")," is the region where ELK AMI will be published to. The published image will be ",(0,i.kt)("em",{parentName:"li"},"private")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"ssl_cert_file_path")," and ",(0,i.kt)("strong",{parentName:"li"},"ssl_cert_key_file_path")," above are the local absolute paths to SSL certificate file and\nSSL certificate key, respectively. They can be ",(0,i.kt)("a",{parentName:"li",href:"https://qubitpi.github.io/hashicorp-aws/blog/certbot"},"obtained via Certbot")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"ssl_nginx_config_file_path")," is the local absolute path to the Nginx config file (see ",(0,i.kt)("strong",{parentName:"li"},"an example")," below) that\nconsumes the SSL certificate above and enables HTTPS.")),(0,i.kt)("h4",{id:"defining-terraform-variables"},"Defining Terraform Variables"),(0,i.kt)("p",null,"Create a file named ",(0,i.kt)("strong",{parentName:"p"},"aws-elk.tfvars")," with the following contents:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-hcl"},'aws_deploy_region = "us-east-2"\nzone_id = "<AWS Route 53 Zone ID>"\nelk_doman = "myelk.mycompany.com"\nkey_pair_name = "<AWS keypair name for SSH>"\ninstance_name = "<AWS EC2 displayed instance name>"\nsecurity_group = "<AWS Security Group for the EC2 instance>"\n')),(0,i.kt)("h4",{id:"defining-config-directory-path"},"Defining Config Directory Path"),(0,i.kt)("p",null,"Put the ",(0,i.kt)("em",{parentName:"p"},"aws-elk.pkrvars.hcl")," and ",(0,i.kt)("em",{parentName:"p"},"aws-elk.tfvars")," in a directory. We will call it ",(0,i.kt)("strong",{parentName:"p"},"ELK_HC_CONFIG_DIR")," (along with\nour source code dir ",(0,i.kt)("strong",{parentName:"p"},"ELK_HC_CONFIG_DIR"),"):"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"ELK_HC_DIR=...\nELK_HC_CONFIG_DIR=/absolute/path/to/hashicorp/elk\n")),(0,i.kt)("admonition",{type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"Make sure ",(0,i.kt)("inlineCode",{parentName:"p"},"*_DIR"),' path does not end with "/", for example, instead of ',(0,i.kt)("inlineCode",{parentName:"p"},"ELK_HC_DIR=/home/ubuntu/config/"),", we should use\n",(0,i.kt)("inlineCode",{parentName:"p"},"ELK_HC_DIR=/home/ubuntu/config"))),(0,i.kt)("p",null,"At the end of the day, the following environment variable (with example values) needs to be defined:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'export HC_DIR=/home/ubuntu/hashicorp-aws/hashicorp/elk\nexport HC_CONFIG_DIR=/home/ubuntu/hashicorp-aws/hashicorp/elk/config-files/\nexport AWS_ACCESS_KEY_ID="LOA8TQ2ZOSKFRLFSHDWC"\nexport AWS_SECRET_ACCESS_KEY="F9Wt082IXjW426QGRdvrsowFhHARt85YlJ2WURri"\n')),(0,i.kt)("h2",{id:"running-script"},"Running Script"),(0,i.kt)("p",null,"After running"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"./deploy.sh\n")),(0,i.kt)("p",null,"record the ",(0,i.kt)("strong",{parentName:"p"},"Elasticsearch password (for ",(0,i.kt)("em",{parentName:"strong"},"elastic")," user)")," at command line prompt. For example"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"==> install-elk.amazon-ebs.elk: + sudo /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\n==> install-elk.amazon-ebs.elk: + yes\n    install-elk.amazon-ebs.elk: This tool will reset the password of the [elastic] user to an autogenerated value.\n    install-elk.amazon-ebs.elk: The password will be printed in the console.\n    install-elk.amazon-ebs.elk:\n    install-elk.amazon-ebs.elk:\n    install-elk.amazon-ebs.elk: Password for the [elastic] user successfully reset.\n    install-elk.amazon-ebs.elk: New value: dsrg34IKHU787iud=dio\n")),(0,i.kt)("p",null,"In this case, the password is ",(0,i.kt)("strong",{parentName:"p"},"dsrg34IKHU787iud=dio")," which is shown in the last line of the output above."),(0,i.kt)("h3",{id:"post-setup-in-ec2-instance"},"Post Setup in EC2 Instance"),(0,i.kt)("p",null,"As we've mentioned in the beginning, this is a semi-deployment and we still need to SSH into the box to manually\ngenerate Kibana token & verification code. This will make the automated deploymentl logic simple and easy to maintain"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'sudo /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token --scope kibana --url "https://localhost:9200"\nsudo /usr/share/kibana/bin/kibana-verification-code\n')),(0,i.kt)("p",null,"Now we can visit ",(0,i.kt)("inlineCode",{parentName:"p"},"https://myelk.mycompany.com")," to enter the token and verification code to access our ELK instance."),(0,i.kt)("h4",{id:"logstash"},"Logstash"),(0,i.kt)("p",null,"Logstash, at this moment, supports redirecting log lines from Filebeat to Elasticsearch and, similar to the\ntoken and verification above, needs to be setup manually."),(0,i.kt)("p",null,"Create a file named ",(0,i.kt)("strong",{parentName:"p"},"logstash-filebeat.conf")," in the default location chosen by Logstash:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo nano /usr/share/logstash/logstash-filebeat.conf\n")),(0,i.kt)("p",null,"Copy and paste the following contents into the file"),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"Replace the ",(0,i.kt)("inlineCode",{parentName:"p"},"<password for user 'elastic'>")," accordingly. If the user is ",(0,i.kt)("em",{parentName:"p"},"elastic"),", which is the case here, the password\nhas been generated during the ",(0,i.kt)("a",{parentName:"p",href:"#building-ami-image"},"AMI image building phase"))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-text"},'input {\n    beats {\n        port => "5044"\n    }\n}\n\noutput {\n    elasticsearch {\n        hosts => [ "https://localhost:9200" ]\n\n        ssl_certificate_verification => false\n\n        user => "elastic"\n\n        password => "<password for user \'elastic\'>"\n    }\n}\n')),(0,i.kt)("p",null,"Start Logstash with:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"sudo /usr/share/logstash/bin/logstash -f logstash-filebeat.conf --config.reload.automatic\n")),(0,i.kt)("p",null,"or with nohup at background:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"nohup sudo /usr/share/logstash/bin/logstash -f logstash-filebeat.conf --config.reload.automatic &\n")))}h.isMDXComponent=!0}}]);